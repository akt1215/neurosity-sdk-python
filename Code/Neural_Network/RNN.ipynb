{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 13:19:42.691587: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-14 13:19:43.589601: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-14 13:19:45.549248: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 13:19:48.852028: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/workspaces/neurosity-sdk-python/Datas/ContinuousReading.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "      <td>15376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.059808</td>\n",
       "      <td>-0.133852</td>\n",
       "      <td>-0.132425</td>\n",
       "      <td>-0.072027</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>-0.001890</td>\n",
       "      <td>-0.063441</td>\n",
       "      <td>-0.107991</td>\n",
       "      <td>-0.097544</td>\n",
       "      <td>-0.024397</td>\n",
       "      <td>0.086587</td>\n",
       "      <td>0.183818</td>\n",
       "      <td>0.220484</td>\n",
       "      <td>0.178699</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.520291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.843658</td>\n",
       "      <td>60.243379</td>\n",
       "      <td>59.818727</td>\n",
       "      <td>59.664639</td>\n",
       "      <td>59.790254</td>\n",
       "      <td>60.178802</td>\n",
       "      <td>60.781713</td>\n",
       "      <td>61.471533</td>\n",
       "      <td>62.124904</td>\n",
       "      <td>62.675335</td>\n",
       "      <td>63.048173</td>\n",
       "      <td>63.168095</td>\n",
       "      <td>63.030173</td>\n",
       "      <td>62.672227</td>\n",
       "      <td>62.136181</td>\n",
       "      <td>61.499387</td>\n",
       "      <td>0.499604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-966.872991</td>\n",
       "      <td>-1003.294097</td>\n",
       "      <td>-1003.891615</td>\n",
       "      <td>-978.956503</td>\n",
       "      <td>-942.469512</td>\n",
       "      <td>-905.186684</td>\n",
       "      <td>-873.198491</td>\n",
       "      <td>-851.338250</td>\n",
       "      <td>-845.446142</td>\n",
       "      <td>-867.442778</td>\n",
       "      <td>-877.260619</td>\n",
       "      <td>-869.758991</td>\n",
       "      <td>-856.674895</td>\n",
       "      <td>-850.145088</td>\n",
       "      <td>-859.271681</td>\n",
       "      <td>-900.666529</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.790274</td>\n",
       "      <td>-7.770336</td>\n",
       "      <td>-7.708088</td>\n",
       "      <td>-7.506101</td>\n",
       "      <td>-7.346275</td>\n",
       "      <td>-7.314130</td>\n",
       "      <td>-7.329459</td>\n",
       "      <td>-7.653278</td>\n",
       "      <td>-7.634746</td>\n",
       "      <td>-7.741315</td>\n",
       "      <td>-7.728402</td>\n",
       "      <td>-7.715148</td>\n",
       "      <td>-7.581876</td>\n",
       "      <td>-7.713318</td>\n",
       "      <td>-7.762769</td>\n",
       "      <td>-7.769855</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.091734</td>\n",
       "      <td>-0.156009</td>\n",
       "      <td>-0.209689</td>\n",
       "      <td>-0.092042</td>\n",
       "      <td>0.151321</td>\n",
       "      <td>0.248125</td>\n",
       "      <td>0.095819</td>\n",
       "      <td>0.041860</td>\n",
       "      <td>-0.038306</td>\n",
       "      <td>-0.110339</td>\n",
       "      <td>-0.060996</td>\n",
       "      <td>0.084692</td>\n",
       "      <td>0.111848</td>\n",
       "      <td>0.196099</td>\n",
       "      <td>0.177093</td>\n",
       "      <td>0.090696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.431759</td>\n",
       "      <td>7.457385</td>\n",
       "      <td>7.415034</td>\n",
       "      <td>7.284918</td>\n",
       "      <td>7.307689</td>\n",
       "      <td>7.443035</td>\n",
       "      <td>7.525624</td>\n",
       "      <td>7.484129</td>\n",
       "      <td>7.380006</td>\n",
       "      <td>7.357147</td>\n",
       "      <td>7.391864</td>\n",
       "      <td>7.515089</td>\n",
       "      <td>7.569289</td>\n",
       "      <td>7.442680</td>\n",
       "      <td>7.459868</td>\n",
       "      <td>7.460488</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1391.999963</td>\n",
       "      <td>1326.110121</td>\n",
       "      <td>1204.212746</td>\n",
       "      <td>1211.093008</td>\n",
       "      <td>1188.815540</td>\n",
       "      <td>1138.625056</td>\n",
       "      <td>1063.885773</td>\n",
       "      <td>1134.946033</td>\n",
       "      <td>1216.126759</td>\n",
       "      <td>1259.260615</td>\n",
       "      <td>1347.420546</td>\n",
       "      <td>1393.286657</td>\n",
       "      <td>1395.583173</td>\n",
       "      <td>1365.989391</td>\n",
       "      <td>1338.888312</td>\n",
       "      <td>1394.045355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A             B             C             D             E  \\\n",
       "count  15376.000000  15376.000000  15376.000000  15376.000000  15376.000000   \n",
       "mean      -0.059808     -0.133852     -0.132425     -0.072027     -0.002587   \n",
       "std       60.843658     60.243379     59.818727     59.664639     59.790254   \n",
       "min     -966.872991  -1003.294097  -1003.891615   -978.956503   -942.469512   \n",
       "25%       -7.790274     -7.770336     -7.708088     -7.506101     -7.346275   \n",
       "50%       -0.091734     -0.156009     -0.209689     -0.092042      0.151321   \n",
       "75%        7.431759      7.457385      7.415034      7.284918      7.307689   \n",
       "max     1391.999963   1326.110121   1204.212746   1211.093008   1188.815540   \n",
       "\n",
       "                  F             G             H             I             J  \\\n",
       "count  15376.000000  15376.000000  15376.000000  15376.000000  15376.000000   \n",
       "mean       0.026648     -0.001890     -0.063441     -0.107991     -0.097544   \n",
       "std       60.178802     60.781713     61.471533     62.124904     62.675335   \n",
       "min     -905.186684   -873.198491   -851.338250   -845.446142   -867.442778   \n",
       "25%       -7.314130     -7.329459     -7.653278     -7.634746     -7.741315   \n",
       "50%        0.248125      0.095819      0.041860     -0.038306     -0.110339   \n",
       "75%        7.443035      7.525624      7.484129      7.380006      7.357147   \n",
       "max     1138.625056   1063.885773   1134.946033   1216.126759   1259.260615   \n",
       "\n",
       "                  K             L             M             N             O  \\\n",
       "count  15376.000000  15376.000000  15376.000000  15376.000000  15376.000000   \n",
       "mean      -0.024397      0.086587      0.183818      0.220484      0.178699   \n",
       "std       63.048173     63.168095     63.030173     62.672227     62.136181   \n",
       "min     -877.260619   -869.758991   -856.674895   -850.145088   -859.271681   \n",
       "25%       -7.728402     -7.715148     -7.581876     -7.713318     -7.762769   \n",
       "50%       -0.060996      0.084692      0.111848      0.196099      0.177093   \n",
       "75%        7.391864      7.515089      7.569289      7.442680      7.459868   \n",
       "max     1347.420546   1393.286657   1395.583173   1365.989391   1338.888312   \n",
       "\n",
       "                  P        Target  \n",
       "count  15376.000000  15376.000000  \n",
       "mean       0.074400      0.520291  \n",
       "std       61.499387      0.499604  \n",
       "min     -900.666529      0.000000  \n",
       "25%       -7.769855      0.000000  \n",
       "50%        0.090696      1.000000  \n",
       "75%        7.460488      1.000000  \n",
       "max     1394.045355      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12300, 16)\n",
      "(3076, 16)\n",
      "(12300,)\n",
      "(3076,)\n"
     ]
    }
   ],
   "source": [
    "# Using segments and segments_labeles to train RNN model using gru layer. \n",
    "# First we need to split the data into training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Target', axis=1).copy(), data[\"Target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Using the data train RNN model using gru layer.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m----> 3\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGRU(\u001b[38;5;241m128\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m), return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      4\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Using the data train RNN model using gru layer.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=20, \n",
    "                    validation_split=0.3, \n",
    "                    batch_size=4,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor = \"val_loss\",\n",
    "                        patience=5,\n",
    "                        restore_best_weights=True)])\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# Save the model\n",
    "model.save('rnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 777600 into shape (243,200,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Reshape the input data to match the input shape of the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m X_train_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m X_test_reshaped \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 777600 into shape (243,200,1)"
     ]
    }
   ],
   "source": [
    "# Build a RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1], 1)),\n",
    "    tf.keras.layers.SimpleRNN(64),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape the input data to match the input shape of the model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save('/workspaces/neurosity-sdk-python/Datas/rnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
